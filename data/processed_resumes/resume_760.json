{
    "education": "Education Details \r\n M.Tech (IT-DBS) B.Tech (CSE)  SRM University\r\nSoftware Engineer \r\n\r\nSoftware Engineer - Larsen and Toubro\r\nSkill Details \r\nCompany Details \r\ncompany - Larsen and Toubro\r\ndescription - Worked as a Software Engineer in Technosoft Corporation, Chennai from Aug 2015 to sep 2016.\r\ncompany - Current Project\r\ndescription - Duration: September 2016 to Till date\r\nVendor: Citi bank\r\nDescription:\r\nCitibank's (Citi) Anti-Money Laundering (AML) Transaction Monitoring (TM) program is a future state solution and a rules-based system for transaction monitoring of ICG-Markets business.\r\nRoles and Responesbilities:\r\n\u00e2\u0080\u00a2 Building and providing domain knowledge for Anti Money Laundering among team members.\r\n\u00e2\u0080\u00a2 The layered architecture has Data Warehouse and Workspace layers which are used by Business Analysts.\r\n\u00e2\u0080\u00a2 Actively involved in designing of star-schema model involving various Dimensions and Fact tables.\r\n\u00e2\u0080\u00a2 Designed SCD2 for maintaining history of the DIM data.\r\n\u00e2\u0080\u00a2 Developing Hive Queries for mapping data between different layers of architecture, and it's usage in Oozie Workflows.\r\n\u00e2\u0080\u00a2 Integration with Data Quality and Reconciliation Module.\r\n\u00e2\u0080\u00a2 Regression and Integration testing of solution for any issues in integration with other modules and effectively testing the data flow from layer-to-layer.\r\n\u00e2\u0080\u00a2 Transaction monitoring system development to generate Alerts for the suspicious and fraudulent transactions based on requirements provide by BAs.\r\n\u00e2\u0080\u00a2 Developing spark Jobs for various business rules.\r\n\u00e2\u0080\u00a2 Learning \"Machine Learning\", which will be used further in the project for developing an effective model for Fraud detection for Anti Money Laundering system.\r\n\u00e2\u0080\u00a2 Scheduling Jobs using Autosys tool.\r\n\u00e2\u0080\u00a2 Deployment and Code Management using RTC and RLM(Release Lifecycle Management)\r\n\r\nHadoop Developer\r\n#  Current Project: PRTS - RAN\r\nEnvironment: Hadoop 2.x, HDFS, Yarn, Hive, Sqoop, HBase, Tez, Tableau, Sqlserver, Teradata\r\nCluster Size: 96 Node Cluster.\r\nDistribution: Horton works - HDP2.3\r\ncompany - Alcatel lucent\r\ndescription - 1X) and  Ruckus Wireless\r\nDescription:\r\nThe scope of this project is to maintain and store the operational and parameters data collected from the multiple vendors networks by the mediation team into the OMS data store and make it available for RF engineers to boost the network performance.\r\nResponsibilities:\r\n\u00e2\u0080\u00a2 Working with Hadoop Distributed File System.\r\n\u00e2\u0080\u00a2 Involved in importing data from MySQL to HDFS using SQOOP.\r\n\u00e2\u0080\u00a2 Involved in creating Hive tables, loading with data and writing hive queries which will run  on top of  Tez execution Engine.\r\n\u00e2\u0080\u00a2 Involved in Preparing Test cases Document.\r\n\u00e2\u0080\u00a2 Involved in Integrating Hive and HBase to store the operational data.\r\n\u00e2\u0080\u00a2 Monitoring the Jobs through Oozie.\r\ncompany - Current Project\r\ndescription - Anti - Money laundering\r\nEnvironment: Hadoop 2.x, HDFS, Yarn, Hive, Oozie, Spark, Unix, Autosys, Python, RTC, RLM, ETL Framwe work\r\nCluster Size: 56 Node Cluster.\r\nDistribution: Cloudera 5.9.14",
    "skills": null,
    "experience": null,
    "summary": "Areas of expertise \u00e2\u0080\u00a2 Big Data Ecosystems: Hadoop-HDFS, MapReduce, Hive, Pig, Sqoop, HBase Oozie, Spark, Pyspark, HUE and having knowledge on cassandra \u00e2\u0080\u00a2 Programming Languages: Python, Core Java and have an idea on Scala \u00e2\u0080\u00a2 Databases: Oracle 10g, MySQL, Sqlserver NoSQL - HBase, Cassandra \u00e2\u0080\u00a2 Tools: Eclipse, Toad, FTP, Tectia, Putty, Autosys, Anaconda, Jupyter notebool and Devops - RTC, RLM. \u00e2\u0080\u00a2 Scripting Languages: JSP \u00e2\u0080\u00a2 Platforms: Windows, UnixEducation Details M.Tech (IT-DBS) B.Tech (CSE)  SRM University Software Engineer",
    "category": "Hadoop"
}